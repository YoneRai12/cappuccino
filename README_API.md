# Llama 3.1-latest + Stable Diffusion API

Llama 3.1-latestï¼ˆãƒãƒ£ãƒƒãƒˆï¼‰ã¨Stable Diffusionï¼ˆç”»åƒç”Ÿæˆï¼‰ã‚’çµ±åˆã—ãŸAPIã§ã™ã€‚æœ€æ–°ã®Llamaãƒ¢ãƒ‡ãƒ«ã¨Stable Diffusionã‚’çµ„ã¿åˆã‚ã›ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã¨ç”»åƒç”Ÿæˆã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚

## ğŸš€ æ©Ÿèƒ½

### åŸºæœ¬æ©Ÿèƒ½
- **Llama 3.1-latestãƒãƒ£ãƒƒãƒˆ**: æœ€æ–°ã®Llama 3.1-latestãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
- **Stable Diffusionç”»åƒç”Ÿæˆ**: Stable Diffusionã‚’ä½¿ç”¨ã—ãŸé«˜å“è³ªç”»åƒç”Ÿæˆ
- **çµ±åˆç”Ÿæˆ**: Llama 3.1-latestã¨Stable Diffusionã‚’çµ„ã¿åˆã‚ã›ãŸæ©Ÿèƒ½
- **ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¬ã‚¹ãƒãƒ³ã‚¹

### ã‚µãƒãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«
- **ãƒãƒ£ãƒƒãƒˆ**: Llama 3.1-latestã€Llama 3.1-8b-latestã€Llama 3.1-70b-latest
- **ç”»åƒç”Ÿæˆ**: Stable Diffusion

## ğŸ“¦ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install fastapi uvicorn aiohttp python-dotenv openai requests pillow
```

## ğŸ”§ è¨­å®š

### ç’°å¢ƒå¤‰æ•°
```bash
# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_API_BASE=https://api.openai.com/v1
STABLE_DIFFUSION_URL=http://localhost:7860
STABLE_DIFFUSION_API_KEY=your_stable_diffusion_api_key_here
```

### Stable Diffusion WebUIã®è¨­å®š
1. Stable Diffusion WebUIã‚’èµ·å‹•
2. `--api`ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ ã—ã¦APIã‚’æœ‰åŠ¹åŒ–
3. å¿…è¦ã«å¿œã˜ã¦APIã‚­ãƒ¼ã‚’è¨­å®š

## ğŸš€ èµ·å‹•

```bash
# APIã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
python api.py

# ã¾ãŸã¯
uvicorn api:app --host 0.0.0.0 --port 8000
```

## ğŸ“š API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

### åŸºæœ¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

#### ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
```bash
GET /health
```

#### ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
```bash
GET /models
```

### Llama 3.1-latestã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

#### Llama 3.1-latestãƒãƒ£ãƒƒãƒˆ
```bash
POST /llm/chat
{
  "prompt": "ã“ã‚“ã«ã¡ã¯ï¼",
  "model": "llama-3.1-latest",
  "temperature": 0.8,
  "max_tokens": 2048
}
```

#### Llama 3.1-latestã‚·ãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒƒãƒˆ
```bash
POST /chat
{
  "message": "Pythonã§è¨ˆç®—æ©Ÿã‚’ä½œæˆã—ã¦ãã ã•ã„",
  "model": "llama-3.1-latest"
}
```

### Stable Diffusionç”»åƒç”Ÿæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

#### Stable Diffusionç”»åƒç”Ÿæˆ
```bash
POST /image/generate
{
  "prompt": "ç¾ã—ã„æ¡œã®èŠ±",
  "negative_prompt": "blurry, low quality",
  "width": 512,
  "height": 512,
  "steps": 20,
  "cfg_scale": 7.5,
  "seed": -1
}
```

### çµ±åˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

#### Llama 3.1-latest+Stable Diffusionç”»åƒç”Ÿæˆ
```bash
POST /llm/generate_with_image
{
  "prompt": "ç¾ã—ã„æ¡œã®èŠ±ã®ç”»åƒã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚ç”»åƒ: æ¡œã®èŠ±",
  "model": "llama-3.1-latest",
  "temperature": 0.8,
  "max_tokens": 2048
}
```

### WebSocket ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

#### Llama 3.1-latestã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒ£ãƒƒãƒˆ
```javascript
const ws = new WebSocket('ws://localhost:8000/chat/stream');
ws.send(JSON.stringify({
  "message": "ã“ã‚“ã«ã¡ã¯ï¼",
  "model": "llama-3.1-latest"
}));
```

## ğŸ§ª ãƒ†ã‚¹ãƒˆ

```bash
# ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
python test_api.py
```

## ğŸ“– ä½¿ç”¨ä¾‹

### Python ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

```python
import aiohttp
import asyncio

async def test_api():
    async with aiohttp.ClientSession() as session:
        # Llama 3.1-latestãƒãƒ£ãƒƒãƒˆ
        async with session.post('http://localhost:8000/llm/chat', json={
            "prompt": "ã“ã‚“ã«ã¡ã¯ï¼",
            "model": "llama-3.1-latest"
        }) as response:
            result = await response.json()
            print(result)
        
        # Stable Diffusionç”»åƒç”Ÿæˆ
        async with session.post('http://localhost:8000/image/generate', json={
            "prompt": "ç¾ã—ã„æ¡œã®èŠ±",
            "width": 512,
            "height": 512
        }) as response:
            result = await response.json()
            print(result)

# å®Ÿè¡Œ
asyncio.run(test_api())
```

### cURL ã‚³ãƒãƒ³ãƒ‰

```bash
# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl http://localhost:8000/health

# Llama 3.1-latestãƒãƒ£ãƒƒãƒˆ
curl -X POST http://localhost:8000/llm/chat \
  -H "Content-Type: application/json" \
  -d '{"prompt": "ã“ã‚“ã«ã¡ã¯ï¼", "model": "llama-3.1-latest"}'

# Stable Diffusionç”»åƒç”Ÿæˆ
curl -X POST http://localhost:8000/image/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt": "ç¾ã—ã„æ¡œã®èŠ±", "width": 512, "height": 512}'

# Llama 3.1-latest+Stable Diffusionç”»åƒç”Ÿæˆ
curl -X POST http://localhost:8000/llm/generate_with_image \
  -H "Content-Type: application/json" \
  -d '{"prompt": "ç¾ã—ã„æ¡œã®èŠ±ã®ç”»åƒã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚ç”»åƒ: æ¡œã®èŠ±", "model": "llama-3.1-latest"}'
```

## ğŸ¦™ Llama 3.1-latestã®ç‰¹å¾´

### Llama 3.1-latestã®è¨­å®š
- **æ¸©åº¦**: 0.8ï¼ˆã‚ˆã‚Šå‰µé€ çš„ãªå‡ºåŠ›ï¼‰
- **æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³**: 2048ï¼ˆã‚ˆã‚Šé•·ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼‰
- **ãƒ¢ãƒ‡ãƒ«**: llama-3.1-latestï¼ˆæœ€æ–°ã®Llamaãƒ¢ãƒ‡ãƒ«ï¼‰

### Llama 3.1-latestã®åˆ©ç‚¹
- **æœ€æ–°æŠ€è¡“**: æœ€æ–°ã®Llama 3.1-latestãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
- **é«˜å“è³ª**: é«˜å“è³ªãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
- **å¤šè¨€èªå¯¾å¿œ**: æ—¥æœ¬èªã‚’å«ã‚€å¤šè¨€èªå¯¾å¿œ
- **å‰µé€ æ€§**: ã‚ˆã‚Šå‰µé€ çš„ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ

## ğŸ¨ Stable Diffusionç”»åƒç”Ÿæˆã®è©³ç´°

### Stable Diffusionãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

- **prompt**: ç”»åƒç”Ÿæˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
- **negative_prompt**: é™¤å¤–ã—ãŸã„è¦ç´ 
- **width/height**: ç”»åƒã‚µã‚¤ã‚ºï¼ˆ512x512æ¨å¥¨ï¼‰
- **steps**: ç”Ÿæˆã‚¹ãƒ†ãƒƒãƒ—æ•°ï¼ˆ20-50æ¨å¥¨ï¼‰
- **cfg_scale**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å¼·åº¦ï¼ˆ7.5æ¨å¥¨ï¼‰
- **seed**: ã‚·ãƒ¼ãƒ‰å€¤ï¼ˆ-1ã§ãƒ©ãƒ³ãƒ€ãƒ ï¼‰

### ç”»åƒç”Ÿæˆã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ä»¥ä¸‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã¨è‡ªå‹•çš„ã«ç”»åƒç”ŸæˆãŒå®Ÿè¡Œã•ã‚Œã¾ã™ï¼š
- "ç”»åƒ"
- "image"
- "picture"
- "draw"
- "generate image"
- "create image"

## ğŸ”§ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### æ–°ã—ã„Llamaãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ 

`api.py`ã®`call_llama`é–¢æ•°ã‚’ä¿®æ­£ã—ã¦æ–°ã—ã„Llamaãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ ã§ãã¾ã™ã€‚

### Stable Diffusionã®è¨­å®šå¤‰æ›´

ç’°å¢ƒå¤‰æ•°ã§Stable Diffusionã®è¨­å®šã‚’å¤‰æ›´ã§ãã¾ã™ï¼š
```bash
STABLE_DIFFUSION_URL=http://your-sd-server:7860
STABLE_DIFFUSION_API_KEY=your-api-key
```

## ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

1. **Llama 3.1-latest APIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼**
   - `.env`ãƒ•ã‚¡ã‚¤ãƒ«ã«æ­£ã—ã„OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
   - APIã‚­ãƒ¼ãŒæœ‰åŠ¹ã‹ç¢ºèª

2. **Stable Diffusionæ¥ç¶šã‚¨ãƒ©ãƒ¼**
   - Stable Diffusion WebUIãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª
   - `--api`ãƒ•ãƒ©ã‚°ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
   - URLã¨ãƒãƒ¼ãƒˆãŒæ­£ã—ã„ã‹ç¢ºèª

3. **ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼**
   - Stable Diffusionã®ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
   - VRAMãŒä¸è¶³ã—ã¦ã„ãªã„ã‹ç¢ºèª

### ãƒ­ã‚°ç¢ºèª

```bash
# ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’DEBUGã«å¤‰æ›´
export LOG_LEVEL=DEBUG
python api.py
```

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸ¤ è²¢çŒ®

ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚„ã‚¤ã‚·ãƒ¥ãƒ¼ã®å ±å‘Šã‚’æ­“è¿ã—ã¾ã™ï¼

## ğŸ“ ã‚µãƒãƒ¼ãƒˆ

å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€GitHubã®ã‚¤ã‚·ãƒ¥ãƒ¼ãƒšãƒ¼ã‚¸ã§å ±å‘Šã—ã¦ãã ã•ã„ã€‚ 