# discordbot/bot.py (ç‰©ç†çš„ã«ãƒ‘ã‚¹å•é¡Œã‚’è§£æ±ºã™ã‚‹æœ€çµ‚ç¢ºå®šç‰ˆ)

import os
import re
import time
import random
import discord
from discord import Status, Activity, ActivityType
import tempfile
import logging
import datetime
import asyncio
import base64
import shutil
from discord import app_commands
from discord.ext import commands
# è¦ªã®ãƒ‘ã‚¹ã¯run_server_bot.pyãŒè¨­å®šã™ã‚‹ã®ã§ã€ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã‚‹
from cappuccino_agent import CappuccinoAgent
import json
import feedparser
import aiohttp
from openai import AsyncOpenAI
from bs4 import BeautifulSoup
from typing import Iterable, Union, Optional, Tuple

from config import settings
from urllib.parse import urlparse, parse_qs, urlunparse
from logging.handlers import RotatingFileHandler
from dotenv import load_dotenv
from dataclasses import dataclass
from typing import Any

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
# â˜…â˜…â˜… ã“ã‚ŒãŒæœ€é‡è¦ã®ä¿®æ­£ç‚¹ã§ã™ â˜…â˜…â˜…
#
# poker.pyãŒåŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ã„ã‚‹ã®ã§ã€.(ãƒ‰ãƒƒãƒˆ)ã‚’ä»˜ã‘ã¦
# ã€Œã“ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚‹poker.pyã€ã¨æ˜ç¤ºã—ã¾ã™ã€‚
from .poker import PokerMatch, PokerView
#
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…


# (ã“ã‚Œä»¥é™ã®ã‚³ãƒ¼ãƒ‰ã¯ã€å‰å›ææ¡ˆã—ãŸæœ€çµ‚ç‰ˆã¨å…¨ãåŒã˜ã§OKã§ã™)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ TOKEN / KEY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPENAI_API_KEY = settings.openai_api_key
OPENAI_API_BASE = settings.openai_api_base
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
NEWS_CONF_FILE = os.path.join(ROOT_DIR, "news_channel.json")
EEW_CONF_FILE = os.path.join(ROOT_DIR, "eew_channel.json")
EEW_LAST_FILE = os.path.join(ROOT_DIR, "last_eew.txt")
WEATHER_CONF_FILE = os.path.join(ROOT_DIR, "weather_channel.json")
def _load_news_channel() -> int:
    try:
        with open(NEWS_CONF_FILE, "r", encoding="utf-8") as f: return int(json.load(f).get("channel_id", 0))
    except Exception: return 0
def _save_news_channel(ch_id: int) -> None:
    try:
        with open(NEWS_CONF_FILE + ".tmp", "w", encoding="utf-8") as f: json.dump({"channel_id": ch_id}, f, ensure_ascii=False, indent=2)
        os.replace(NEWS_CONF_FILE + ".tmp", NEWS_CONF_FILE)
    except Exception as e: logger.error("failed to save news channel: %s", e)
def _load_eew_channel() -> int:
    try:
        with open(EEW_CONF_FILE, "r", encoding="utf-8") as f: return int(json.load(f).get("channel_id", 0))
    except Exception: return 0
def _save_eew_channel(ch_id: int) -> None:
    try:
        with open(EEW_CONF_FILE + ".tmp", "w", encoding="utf-8") as f: json.dump({"channel_id": ch_id}, f, ensure_ascii=False, indent=2)
        os.replace(EEW_CONF_FILE + ".tmp", EEW_CONF_FILE)
    except Exception as e: logger.error("failed to save eew channel: %s", e)
def _load_weather_channel() -> int:
    try:
        with open(WEATHER_CONF_FILE, "r", encoding="utf-8") as f: return int(json.load(f).get("channel_id", 0))
    except Exception: return 0
def _save_weather_channel(ch_id: int) -> None:
    try:
        with open(WEATHER_CONF_FILE + ".tmp", "w", encoding="utf-8") as f: json.dump({"channel_id": ch_id}, f, ensure_ascii=False, indent=2)
        os.replace(WEATHER_CONF_FILE + ".tmp", WEATHER_CONF_FILE)
    except Exception as e: logger.error("failed to save weather channel: %s", e)
def _load_last_eew() -> str:
    try:
        with open(EEW_LAST_FILE, "r", encoding="utf-8") as f: return f.read().strip()
    except Exception: return ""
def _save_last_eew(eid: str) -> None:
    try:
        with open(EEW_LAST_FILE, "w", encoding="utf-8") as f: f.write(eid)
    except Exception as e: logger.error("failed to save eew id: %s", e)
NEWS_CHANNEL_ID = _load_news_channel()
EEW_CHANNEL_ID = _load_eew_channel()
LAST_EEW_ID = _load_last_eew()
WEATHER_CHANNEL_ID = _load_weather_channel()
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# api_baseãŒNoneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
api_base = OPENAI_API_BASE if OPENAI_API_BASE else "https://api.openai.com/v1"
cappuccino_agent = CappuccinoAgent(api_key=OPENAI_API_KEY, api_base=api_base)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ­ã‚®ãƒ³ã‚°è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log_file_path = os.path.join(ROOT_DIR, "..", "bot.log")
handler = RotatingFileHandler(log_file_path, maxBytes=1_000_000, backupCount=5, encoding='utf-8')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[handler])
logging.getLogger('discord').setLevel(logging.WARNING)
logger = logging.getLogger(__name__)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Discordã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
intents = discord.Intents.default()
intents.message_content = True
intents.guilds = True
intents.members = True
bot = commands.Bot(command_prefix="y!", intents=intents)

# GPUç›£è¦–æ©Ÿèƒ½ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from docker_tools import nvidia_smi_status, nvidia_smi_memory_usage, nvidia_smi_processes
    GPU_MONITORING_AVAILABLE = True
except ImportError:
    GPU_MONITORING_AVAILABLE = False
    logger.warning("GPU monitoring tools not available")
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def _gather_reply_chain(msg: discord.Message, limit: int | None = None) -> list[discord.Message]:
    chain: list[discord.Message] = []
    current = msg
    while getattr(current, "reference", None):
        if limit is not None and len(chain) >= limit: break
        try: 
            # message_idãŒNoneã§ãªã„ã“ã¨ã‚’ç¢ºèª
            if current.reference and current.reference.message_id:
                current = await msg.channel.fetch_message(current.reference.message_id)
            else:
                break
        except Exception: break
        chain.append(current)
    chain.reverse()
    return chain
def _strip_bot_mention(text: str) -> str:
    if bot.user is None: return text.strip()
    return re.sub(fr"<@!?{bot.user.id}>", "", text).strip()
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ AIå¿œç­”å‡¦ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def handle_agent_request(message: discord.Message, user_text: str):
    if not user_text.strip():
        await message.reply("è³ªå•ã‚’æ›¸ã„ã¦ã­ï¼")
        return
    reply = await message.reply("æ€è€ƒä¸­...")
    try:
        history = await _gather_reply_chain(message, limit=5)
        full_prompt = "\n".join([f"{m.author.display_name}: {m.content}" for m in history if m.content])
        full_prompt += f"\n{message.author.display_name}: {user_text}"

        final_answer = await cappuccino_agent.run(full_prompt)
        logger.info(f"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ã®æœ€çµ‚å›ç­”: {final_answer}")

        # ãƒ‘ã‚¹ãŒå«ã¾ã‚Œã‚‹ã‹ã©ã†ã‹å³å¯†ã«åˆ¤å®š
        image_path = None
        response_text = str(final_answer)

        import re
        # Windowsãƒ‘ã‚¹ã®æ­£è¦è¡¨ç¾ï¼ˆç°¡æ˜“ï¼‰
        m = re.search(r"([A-Za-z]:\\(?:[^\\/:*?\"<>|\r\n]+\\)*[^\\/:*?\"<>|\r\n]+\.png)", final_answer)
        if m:
            path_str = m.group(1)
            if os.path.exists(path_str):
                image_path = path_str
                response_text = "ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼"
            else:
                response_text = f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ãƒ‘ã‚¹: {path_str}"

        if image_path:
            await reply.edit(content=response_text, attachments=[discord.File(image_path)])
            try:
                os.remove(image_path)
            except Exception as e:
                logger.error(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¤±æ•—: {e}")
        else:
            if not response_text.strip():
                response_text = "(ç©ºã®å¿œç­”)"
            for i in range(0, len(response_text), 1950):
                chunk = response_text[i:i+1950]
                if i == 0:
                    await reply.edit(content=chunk)
                else:
                    await message.channel.send(chunk)

    except Exception as exc:
        logger.error(f"handle_agent_requestã§ã‚¨ãƒ©ãƒ¼: {exc}", exc_info=True)
        await reply.edit(content=f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {exc}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Discordã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@bot.event
async def on_message(message: discord.Message):
    if message.author == bot.user: return
    # å‚ç…§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å®‰å…¨ãªãƒã‚§ãƒƒã‚¯
    is_reply_to_bot = False
    if message.reference and message.reference.resolved:
        try:
            # DeletedReferencedMessageã®å ´åˆã¯authorãŒå­˜åœ¨ã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹
            resolved = message.reference.resolved
            # å‹ãƒã‚§ãƒƒã‚¯ã‚’å›é¿ã™ã‚‹ãŸã‚ã«getattrã‚’ä½¿ç”¨
            author = getattr(resolved, 'author', None)
            if (author is not None and 
                bot.user is not None and 
                author == bot.user):
                is_reply_to_bot = True
        except (AttributeError, TypeError):
            pass
    
    if bot.user in message.mentions or is_reply_to_bot:
        await handle_agent_request(message, _strip_bot_mention(message.content))
    if message.content.startswith("r?"): # ã‚³ãƒãƒ³ãƒ‰ã¯ r? ã®ã¾ã¾
        await handle_agent_request(message, message.content[2:].strip())
@bot.event
async def on_ready():
    await bot.change_presence(status=Status.online, activity=Activity(type=ActivityType.playing, name="r? | @ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ | /gpu"))
    if bot.user:
        logger.info(f"LOGIN: {bot.user} (ID: {bot.user.id})")
    else:
        logger.info("LOGIN: Bot user not available")
    
    # ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ã‚’åŒæœŸ
    try:
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚³ãƒãƒ³ãƒ‰ã¨ã—ã¦åŒæœŸ
        synced = await bot.tree.sync()
        logger.info(f"Synced {len(synced)} global command(s): {[cmd.name for cmd in synced]}")
        
        # é–‹ç™ºç”¨ï¼šç‰¹å®šã®ã‚®ãƒ«ãƒ‰ã«ã‚³ãƒãƒ³ãƒ‰ã‚’åŒæœŸ
        # æ³¨æ„: æœ¬ç•ªç’°å¢ƒã§ã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«åŒæœŸã®ã¿ã‚’ä½¿ç”¨
        for guild in bot.guilds:
            try:
                synced_guild = await bot.tree.sync(guild=guild)
                logger.info(f"Synced {len(synced_guild)} command(s) to guild {guild.name}: {[cmd.name for cmd in synced_guild]}")
            except Exception as e:
                logger.error(f"Failed to sync commands to guild {guild.name}: {e}")
                
    except Exception as e:
        logger.error(f"Failed to sync commands: {e}")
        
    # ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
    logger.info(f"Available commands: {[cmd.name for cmd in bot.tree.get_commands()]}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@bot.tree.command(name="gpu", description="GPUä½¿ç”¨ç‡ã‚’ç¢ºèªã—ã¾ã™")
@app_commands.describe()
async def gpu_status(interaction: discord.Interaction):
    """GPUä½¿ç”¨ç‡ã‚’ç¢ºèªã™ã‚‹ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰"""
    if not GPU_MONITORING_AVAILABLE:
        await interaction.response.send_message("âŒ GPUç›£è¦–æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚", ephemeral=True)
        return
    
    await interaction.response.defer()
    
    try:
        # GPUçŠ¶æ…‹ã‚’å–å¾—
        status = nvidia_smi_status()
        
        if "error" in status:
            await interaction.followup.send(f"âŒ GPUçŠ¶æ…‹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {status['error']}")
            return
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—
        memory = nvidia_smi_memory_usage()
        
        # ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±ã‚’å–å¾—
        processes = nvidia_smi_processes()
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä½œæˆ
        embed = discord.Embed(
            title="ğŸ–¥ï¸ GPU Status",
            color=discord.Color.blue(),
            timestamp=discord.utils.utcnow()
        )
        
        if "gpu_info" in status and status["gpu_info"]:
            for gpu in status["gpu_info"]:
                memory_usage = "Unknown"
                if "memory_usage" in memory and memory["memory_usage"]:
                    for mem in memory["memory_usage"]:
                        if mem["gpu_index"] == gpu["index"]:
                            memory_usage = f"{mem['used_mb']}MB / {mem['total_mb']}MB ({mem['usage_percent']}%)"
                            break
                
                embed.add_field(
                    name=f"ğŸ® GPU {gpu['index']}: {gpu['name']}",
                    value=f"ğŸ’¾ Memory: {memory_usage}\n"
                          f"âš¡ Utilization: {gpu['utilization_percent']}%\n"
                          f"ğŸŒ¡ï¸ Temperature: {gpu['temperature_c']}Â°C",
                    inline=False
                )
        else:
            embed.add_field(name="Info", value="No GPU information available", inline=False)
        
        # ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±ã‚’è¿½åŠ 
        if "processes" in processes and processes["processes"]:
            process_lines = processes["processes"].strip().split('\n')
            if len(process_lines) > 2:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’é™¤ã
                process_info = "\n".join(process_lines[2:5])  # æœ€åˆã®3ã¤ã®ãƒ—ãƒ­ã‚»ã‚¹
                embed.add_field(name="ğŸ”„ Active Processes", value=f"```\n{process_info}\n```", inline=False)
        
        await interaction.followup.send(embed=embed)
        
    except Exception as e:
        logger.error(f"GPU status command error: {e}")
        await interaction.followup.send(f"âŒ GPUçŠ¶æ…‹ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


@bot.tree.command(name="gpumemory", description="GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®è©³ç´°ã‚’è¡¨ç¤ºã—ã¾ã™")
@app_commands.describe()
async def gpu_memory(interaction: discord.Interaction):
    """GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰"""
    if not GPU_MONITORING_AVAILABLE:
        await interaction.response.send_message("âŒ GPUç›£è¦–æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚", ephemeral=True)
        return
    
    await interaction.response.defer()
    
    try:
        memory = nvidia_smi_memory_usage()
        
        if "error" in memory:
            await interaction.followup.send(f"âŒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {memory['error']}")
            return
        
        embed = discord.Embed(
            title="ğŸ’¾ GPU Memory Usage",
            color=discord.Color.green(),
            timestamp=discord.utils.utcnow()
        )
        
        if "memory_usage" in memory and memory["memory_usage"]:
            for mem in memory["memory_usage"]:
                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ã«åŸºã¥ã„ã¦è‰²ã‚’æ±ºå®š
                usage_percent = mem["usage_percent"]
                if usage_percent > 80:
                    color = discord.Color.red()
                elif usage_percent > 60:
                    color = discord.Color.orange()
                else:
                    color = discord.Color.green()
                
                embed.add_field(
                    name=f"ğŸ® GPU {mem['gpu_index']}: {mem['name']}",
                    value=f"ğŸ’¾ Used: {mem['used_mb']}MB\n"
                          f"ğŸ“Š Free: {mem['free_mb']}MB\n"
                          f"ğŸ“ˆ Total: {mem['total_mb']}MB\n"
                          f"ğŸ“Š Usage: {usage_percent}%",
                    inline=True
                )
        else:
            embed.add_field(name="Info", value="No memory information available", inline=False)
        
        await interaction.followup.send(embed=embed)
        
    except Exception as e:
        logger.error(f"GPU memory command error: {e}")
        await interaction.followup.send(f"âŒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


@bot.tree.command(name="gpuprocesses", description="GPUã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’è¡¨ç¤ºã—ã¾ã™")
@app_commands.describe()
async def gpu_processes(interaction: discord.Interaction):
    """GPUã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’è¡¨ç¤ºã™ã‚‹ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰"""
    if not GPU_MONITORING_AVAILABLE:
        await interaction.response.send_message("âŒ GPUç›£è¦–æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚", ephemeral=True)
        return
    
    await interaction.response.defer()
    
    try:
        processes = nvidia_smi_processes()
        
        if "error" in processes:
            await interaction.followup.send(f"âŒ ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {processes['error']}")
            return
        
        embed = discord.Embed(
            title="ğŸ”„ GPU Processes",
            color=discord.Color.purple(),
            timestamp=discord.utils.utcnow()
        )
        
        if "processes" in processes and processes["processes"]:
            process_lines = processes["processes"].strip().split('\n')
            if len(process_lines) > 2:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’é™¤ã
                # ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±ã‚’æ•´å½¢
                process_info = "\n".join(process_lines[2:10])  # æœ€åˆã®8ã¤ã®ãƒ—ãƒ­ã‚»ã‚¹
                embed.add_field(
                    name="Active Processes", 
                    value=f"```\n{process_info}\n```", 
                    inline=False
                )
            else:
                embed.add_field(name="Info", value="No processes using GPU", inline=False)
        else:
            embed.add_field(name="Info", value="No process information available", inline=False)
        
        await interaction.followup.send(embed=embed)
        
    except Exception as e:
        logger.error(f"GPU processes command error: {e}")
        await interaction.followup.send(f"âŒ ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ èµ·å‹•ç”¨é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def start_bot():
    """ãƒœãƒƒãƒˆã‚’èµ·å‹•ã™ã‚‹ãŸã‚ã®éåŒæœŸé–¢æ•°"""
    load_dotenv(os.path.join(os.path.dirname(__file__), "..", ".env"))
    TOKEN = os.getenv("DISCORD_BOT_TOKEN")
    if not TOKEN:
        logger.error("DISCORD_BOT_TOKEN is not set.")
        return
    await bot.start(TOKEN)